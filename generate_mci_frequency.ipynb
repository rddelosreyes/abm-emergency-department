{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frequency distribution of disposition and complexity per acuity\n",
    "df_frequency = pd.read_csv('params/frequency/frequency_groupname.csv', dtype={'acuity': str, 'disposition': str, 'complexity': str, 'percent': float})\n",
    "\n",
    "# Add column for retrospective cohort groupname and endgroup\n",
    "df_frequency['groupname'] = df_frequency['acuity'].astype(str) + '-' + df_frequency['disposition'] + '-' + df_frequency['complexity']\n",
    "df_frequency['endgroup'] = df_frequency['disposition'] + '-' + df_frequency['complexity']\n",
    "\n",
    "dict_frequency = df_frequency.set_index('groupname').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative and total frequencies for admitted and not admitted dispositions\n",
    "dict_relative_frequency = {}\n",
    "dict_total_frequency = {}\n",
    "for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "    dict_relative_frequency[acuity_val] = {}\n",
    "    dict_total_frequency[acuity_val] = {}\n",
    "    for disp_val in ['HOME', 'ICU', 'WARD']:\n",
    "        for comp_val in ['LOW', 'MODERATE', 'HIGH']:\n",
    "            endgroup_val = disp_val + '-' + comp_val\n",
    "            dict_relative_frequency[acuity_val][endgroup_val] = 0\n",
    "            dict_total_frequency[acuity_val][endgroup_val] = 0\n",
    "\n",
    "for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "    df_acuity = df_frequency[df_frequency['acuity'] == acuity_val]\n",
    "\n",
    "    df_disposition_admitted = df_acuity[df_acuity['disposition'].isin(['WARD', 'ICU'])].copy()\n",
    "    df_disposition_admitted['relative_freq'] = df_disposition_admitted['percent'] / df_disposition_admitted['percent'].sum()\n",
    "\n",
    "    df_disposition_notadmitted = df_acuity[~df_acuity['disposition'].isin(['WARD', 'ICU'])].copy()\n",
    "    df_disposition_notadmitted['relative_freq'] = df_disposition_notadmitted['percent'] / df_disposition_notadmitted['percent'].sum()\n",
    "\n",
    "    for idx, row in df_disposition_admitted.iterrows():\n",
    "        dict_relative_frequency[row['acuity']][row['endgroup']] = row['relative_freq']\n",
    "        dict_total_frequency[row['acuity']][row['endgroup']] = df_disposition_admitted['percent'].sum()\n",
    "\n",
    "    for idx, row in df_disposition_notadmitted.iterrows():\n",
    "        dict_relative_frequency[row['acuity']][row['endgroup']] = row['relative_freq']\n",
    "        dict_total_frequency[row['acuity']][row['endgroup']] = df_disposition_notadmitted['percent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase frequency of high-complexity patients\n",
    "for increase_val in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    acuity_row = []\n",
    "    disposition_row = []\n",
    "    complexity_row = []\n",
    "    percent_row = []\n",
    "    for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "        for disp_val in ['HOME', 'WARD', 'ICU']:\n",
    "            for comp_val in ['LOW', 'MODERATE', 'HIGH']:\n",
    "                grpname_val = acuity_val + '-' + disp_val + '-' + comp_val\n",
    "                endgrp_val = disp_val + '-' + comp_val\n",
    "\n",
    "                if grpname_val in df_frequency['groupname'].tolist():\n",
    "                    if acuity_val != '5':\n",
    "                        if disp_val in ['WARD', 'ICU']:\n",
    "                            percent_row.append(min((dict_total_frequency[acuity_val][endgrp_val] + increase_val), 1) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "                        else:\n",
    "                            percent_row.append(max((dict_total_frequency[acuity_val][endgrp_val] - increase_val), 0) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "                    else:\n",
    "                        # acuity 5 only has ward disposition, so don't add for ICU\n",
    "                        if disp_val in ['WARD']:\n",
    "                            percent_row.append(min((dict_total_frequency[acuity_val][endgrp_val] + increase_val), 1) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "                        else:\n",
    "                            percent_row.append(max((dict_total_frequency[acuity_val][endgrp_val] - increase_val), 0) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "\n",
    "                    acuity_row.append(acuity_val)\n",
    "                    disposition_row.append(disp_val)\n",
    "                    complexity_row.append(comp_val)\n",
    "\n",
    "    df_new_frequency = pd.DataFrame.from_dict({'acuity': acuity_row, 'disposition': disposition_row, 'complexity': complexity_row, 'percent': percent_row}).sort_values(['acuity', 'disposition', 'complexity'])\n",
    "\n",
    "    # Verify that sum of frequency distribution is equal to 1\n",
    "    print('---', increase_val)\n",
    "    print(df_new_frequency.groupby('acuity').percent.sum())\n",
    "\n",
    "    # Save new frequency distribution\n",
    "    df_new_frequency.to_csv(f'params/frequency/frequency_groupname_disposition_{int(increase_val*10)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative and total frequencies for high and non-high complexity\n",
    "dict_relative_frequency = {}\n",
    "dict_total_frequency = {}\n",
    "for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "    dict_relative_frequency[acuity_val] = {}\n",
    "    dict_total_frequency[acuity_val] = {}\n",
    "    for disp_val in ['HOME', 'ICU', 'WARD']:\n",
    "        for comp_val in ['LOW', 'MODERATE', 'HIGH']:\n",
    "            endgroup_val = disp_val + '-' + comp_val\n",
    "            dict_relative_frequency[acuity_val][endgroup_val] = 0\n",
    "            dict_total_frequency[acuity_val][endgroup_val] = 0\n",
    "\n",
    "for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "    df_acuity = df_frequency[df_frequency['acuity'] == acuity_val]\n",
    "\n",
    "    df_complexity_high = df_acuity[df_acuity['complexity'].isin(['HIGH'])].copy()\n",
    "    df_complexity_high['relative_freq'] = df_complexity_high['percent'] / df_complexity_high['percent'].sum()\n",
    "\n",
    "    df_complexity_nonhigh = df_acuity[~df_acuity['complexity'].isin(['HIGH'])].copy()\n",
    "    df_complexity_nonhigh['relative_freq'] = df_complexity_nonhigh['percent'] / df_complexity_nonhigh['percent'].sum()\n",
    "\n",
    "    for idx, row in df_complexity_high.iterrows():\n",
    "        dict_relative_frequency[row['acuity']][row['endgroup']] = row['relative_freq']\n",
    "        dict_total_frequency[row['acuity']][row['endgroup']] = df_complexity_high['percent'].sum()\n",
    "\n",
    "    for idx, row in df_complexity_nonhigh.iterrows():\n",
    "        dict_relative_frequency[row['acuity']][row['endgroup']] = row['relative_freq']\n",
    "        dict_total_frequency[row['acuity']][row['endgroup']] = df_complexity_nonhigh['percent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase frequency of high-complexity patients\n",
    "for increase_val in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    acuity_row = []\n",
    "    disposition_row = []\n",
    "    complexity_row = []\n",
    "    percent_row = []\n",
    "    for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "        for disp_val in ['HOME', 'WARD', 'ICU']:\n",
    "            for comp_val in ['LOW', 'MODERATE', 'HIGH']:\n",
    "                grpname_val = acuity_val + '-' + disp_val + '-' + comp_val\n",
    "                endgrp_val = disp_val + '-' + comp_val\n",
    "\n",
    "                if grpname_val in df_frequency['groupname'].tolist():\n",
    "                    if acuity_val != '5':\n",
    "                        if comp_val in ['HIGH']:\n",
    "                            percent_row.append(min((dict_total_frequency[acuity_val][endgrp_val] + increase_val), 1) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "                        else:\n",
    "                            percent_row.append(max((dict_total_frequency[acuity_val][endgrp_val] - increase_val), 0) * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "                    else:\n",
    "                        # acuity 5 does not have high complexity, so retain frequency distribution as is\n",
    "                        percent_row.append(dict_total_frequency[acuity_val][endgrp_val] * dict_relative_frequency[acuity_val][endgrp_val])\n",
    "\n",
    "                    acuity_row.append(acuity_val)\n",
    "                    disposition_row.append(disp_val)\n",
    "                    complexity_row.append(comp_val)\n",
    "\n",
    "    df_new_frequency = pd.DataFrame.from_dict({'acuity': acuity_row, 'disposition': disposition_row, 'complexity': complexity_row, 'percent': percent_row}).sort_values(['acuity', 'disposition', 'complexity'])\n",
    "\n",
    "    # Verify that sum of frequency distribution is equal to 1\n",
    "    print('---', increase_val)\n",
    "    print(df_new_frequency.groupby('acuity').percent.sum())\n",
    "\n",
    "    # Save new frequency distribution\n",
    "    df_new_frequency.to_csv(f'params/frequency/frequency_groupname_complexity_{int(increase_val*10)}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
