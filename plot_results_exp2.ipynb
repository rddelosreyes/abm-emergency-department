{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_type = 'experiment_2'\n",
    "runid = '1'\n",
    "runid_foldername = [foldername for foldername in os.listdir(f'experiments/{simulation_type}') if foldername == f'output_{runid}'][0]\n",
    "output_folder = f'experiments/{simulation_type}/{runid_foldername}'\n",
    "\n",
    "seed_list = []\n",
    "file_list = os.listdir(f'{output_folder}')\n",
    "for file in file_list:\n",
    "    if 'seed' in file:\n",
    "        seed_list.append(file.split('_')[1])\n",
    "seed_list = list(set(seed_list))\n",
    "\n",
    "results_list = []\n",
    "for seed in tqdm(seed_list):\n",
    "    df_seed = pd.read_csv(f'{output_folder}/seed_{seed}', usecols=['ed_los', 'destination_record'], dtype={'ed_los': int, 'destination_record': str})\n",
    "    df_seed['ed_los'] = df_seed['ed_los'] / 60\n",
    "    df_seed['case_len'] = df_seed.destination_record.str.len()\n",
    "    results_list.append(df_seed)\n",
    "df_pro = pd.concat(results_list)\n",
    "\n",
    "simulation_type = 'experiment_2'\n",
    "runid = '2'\n",
    "runid_foldername = [foldername for foldername in os.listdir(f'experiments/{simulation_type}') if foldername == f'output_{runid}'][0]\n",
    "output_folder = f'experiments/{simulation_type}/{runid_foldername}'\n",
    "\n",
    "seed_list = []\n",
    "file_list = os.listdir(f'{output_folder}')\n",
    "for file in file_list:\n",
    "    if 'seed' in file:\n",
    "        seed_list.append(file.split('_')[1])\n",
    "seed_list = list(set(seed_list))\n",
    "\n",
    "results_list = []\n",
    "for seed in tqdm(seed_list):\n",
    "    df_seed = pd.read_csv(f'{output_folder}/seed_{seed}', usecols=['ed_los', 'destination_record'], dtype={'ed_los': int, 'destination_record': str})\n",
    "    df_seed['ed_los'] = df_seed['ed_los'] / 60\n",
    "    df_seed['case_len'] = df_seed.destination_record.str.len()\n",
    "    results_list.append(df_seed)\n",
    "df_ret = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acuity = ['1', '2', '3', '4', '5']\n",
    "list_disposition = ['HOME', 'WARD', 'ICU']\n",
    "list_complexity = ['LOW', 'MODERATE', 'HIGH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target LOS distributions\n",
    "with open(f'params/los/los_overall.txt') as filehandle:\n",
    "    target_los_all = json.load(filehandle)\n",
    "\n",
    "target_los_acuity = {}\n",
    "for acuity_val in list_acuity:\n",
    "    with open(f'params/los/los_acuity_{acuity_val}.txt') as filehandle:\n",
    "        target_los_acuity[acuity_val] = json.load(filehandle)\n",
    "\n",
    "target_los_disposition = {}\n",
    "for disposition_val in list_disposition:\n",
    "    with open(f'params/los/los_disposition_{disposition_val}.txt') as filehandle:\n",
    "        target_los_disposition[disposition_val] = json.load(filehandle)\n",
    "\n",
    "target_los_complexity = {}\n",
    "for complexity_val in list_complexity:\n",
    "    with open(f'params/los/los_complexity_{complexity_val}.txt') as filehandle:\n",
    "        target_los_complexity[complexity_val] = json.load(filehandle)\n",
    "\n",
    "target_los_acuity_disposition = {}\n",
    "target_los_acuity_complexity = {}\n",
    "for acuity_val in list_acuity:\n",
    "    for disposition_val in list_disposition:\n",
    "        los_disposition = []\n",
    "        for complexity_val in list_complexity:\n",
    "            try:\n",
    "                with open(f'params/los/los_groupname_{acuity_val}-{disposition_val}-{complexity_val}.txt') as filehandle:\n",
    "                    los_temp = json.load(filehandle)\n",
    "                    los_disposition.extend(los_temp)\n",
    "            except:\n",
    "                continue\n",
    "        target_los_acuity_disposition[f'{acuity_val}_{disposition_val}'] = los_disposition\n",
    "\n",
    "    for complexity_val in list_complexity:\n",
    "        los_complexity = []\n",
    "        for disposition_val in list_disposition:\n",
    "            try:\n",
    "                with open(f'params/los/los_groupname_{acuity_val}-{disposition_val}-{complexity_val}.txt') as filehandle:\n",
    "                    los_temp = json.load(filehandle)\n",
    "                    los_complexity.extend(los_temp)\n",
    "            except:\n",
    "                continue\n",
    "        target_los_acuity_complexity[f'{acuity_val}_{complexity_val}'] = los_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_statistics(results_list):\n",
    "\n",
    "    if len(results_list) > 0:\n",
    "\n",
    "        return round(np.median(results_list), 1), round(np.quantile(results_list, 0.25), 1), round(np.quantile(results_list, 0.75), 1)\n",
    "    else:\n",
    "\n",
    "        return 'N/A', 'N/A', 'N/A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_los(los_all, los_acuity, los_disposition, los_complexity, los_acuity_disposition, los_acuity_complexity):\n",
    "    print('overall', get_distribution_statistics(los_all))\n",
    "\n",
    "    print('--- Acuity')\n",
    "    for acuity_val in list_acuity:\n",
    "        print(acuity_val, get_distribution_statistics(los_acuity[acuity_val]))\n",
    "\n",
    "    print('--- Disposition')\n",
    "    for disposition_val in list_disposition:\n",
    "        print(disposition_val, get_distribution_statistics(los_disposition[disposition_val]))\n",
    "\n",
    "    print('--- Complexity')\n",
    "    for complexity_val in list_complexity:\n",
    "        print(complexity_val, get_distribution_statistics(los_complexity[complexity_val]))\n",
    "\n",
    "    print('--- Acuity x Disposition')\n",
    "    for disposition_val in list_disposition:\n",
    "        for acuity_val in list_acuity:\n",
    "            print(acuity_val, disposition_val, get_distribution_statistics(los_acuity_disposition[f'{acuity_val}_{disposition_val}']))\n",
    "\n",
    "    print('--- Acuity x Complexity')\n",
    "    for complexity_val in list_complexity:\n",
    "        for acuity_val in list_acuity:\n",
    "            print(acuity_val, complexity_val, get_distribution_statistics(los_acuity_complexity[f'{acuity_val}_{complexity_val}']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(simulation_type, run_id):\n",
    "    runid_foldername = [foldername for foldername in os.listdir(f'experiments/{simulation_type}') if foldername == f'output_{run_id}'][0]\n",
    "    output_folder = f'experiments/{simulation_type}/{runid_foldername}'\n",
    "\n",
    "    seed_list = []\n",
    "    file_list = os.listdir(f'{output_folder}')\n",
    "    for file in file_list:\n",
    "        if 'seed' in file:\n",
    "            seed_list.append(file.split('_')[1])\n",
    "    seed_list = list(set(seed_list))\n",
    "\n",
    "    df_results_concatenated = pd.DataFrame()\n",
    "    df_results_per_run = []\n",
    "    for seed in tqdm(seed_list):\n",
    "        df_seed = pd.read_csv(f'{output_folder}/seed_{seed}', dtype={'acuity': str, 'disposition': str, 'complexity': str, 'ed_los': float})\n",
    "        df_seed['ed_los'] = df_seed['ed_los'] / 60\n",
    "        df_seed['case_len'] = df_seed.destination_record.str.len()\n",
    "\n",
    "        df_results_per_run.append(df_seed)\n",
    "    df_results_concatenated = pd.concat(df_results_per_run)\n",
    "\n",
    "    return df_results_concatenated, df_results_per_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro_concatenated, df_pro_per_run = load_results('experiment_2', '1')\n",
    "df_ret_concatenated, df_ret_per_run = load_results('experiment_2', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Target distributions')\n",
    "print_los(target_los_all, target_los_acuity, target_los_disposition, target_los_complexity, target_los_acuity_disposition, target_los_acuity_complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, cohort_type in zip([df_pro_concatenated, df_ret_concatenated], ['Prospective', 'Retrospective']):\n",
    "    print(f'\\n=== {cohort_type} cohort type')\n",
    "\n",
    "    cohort_los_all = df_cohort['ed_los']\n",
    "\n",
    "    cohort_los_acuity = {}\n",
    "    for acuity_val in list_acuity:\n",
    "        cohort_los_acuity[acuity_val] = df_cohort[df_cohort['acuity'] == acuity_val]['ed_los']\n",
    "\n",
    "    cohort_los_disposition = {}\n",
    "    for disposition_val in list_disposition:\n",
    "        cohort_los_disposition[disposition_val] = df_cohort[df_cohort['disposition'] == disposition_val]['ed_los']\n",
    "\n",
    "    cohort_los_complexity = {}\n",
    "    for complexity_val in list_complexity:\n",
    "        cohort_los_complexity[complexity_val] = df_cohort[df_cohort['complexity'] == complexity_val]['ed_los']\n",
    "\n",
    "    cohort_los_acuity_disposition = {}\n",
    "    cohort_los_acuity_complexity = {}\n",
    "    for acuity_val in list_acuity:\n",
    "        for disposition_val in list_disposition:\n",
    "            cohort_los_acuity_disposition[f'{acuity_val}_{disposition_val}'] = df_cohort[(df_cohort['acuity'] == acuity_val) & (df_cohort['disposition'] == disposition_val)]['ed_los']\n",
    "\n",
    "        for complexity_val in list_complexity:\n",
    "            cohort_los_acuity_complexity[f'{acuity_val}_{complexity_val}'] = df_cohort[(df_cohort['acuity'] == acuity_val) & (df_cohort['complexity'] == complexity_val)]['ed_los']\n",
    "\n",
    "    print_los(cohort_los_all, cohort_los_acuity, cohort_los_disposition,cohort_los_complexity, cohort_los_acuity_disposition, cohort_los_acuity_complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_los_difference(df_results_per_run, target_results, indicator_type):\n",
    "    if indicator_type == 'all':\n",
    "        dict_los_difference = {'all': []}\n",
    "        for df_run in df_results_per_run:\n",
    "            los_difference = np.median(df_run['ed_los']) - np.median(target_results)\n",
    "            dict_los_difference['all'].append(los_difference)\n",
    "    elif indicator_type == 'acuity':\n",
    "        dict_los_difference = {}\n",
    "        for acuity_val in list_acuity:\n",
    "            dict_los_difference[acuity_val] = []\n",
    "            for df_run in df_results_per_run:\n",
    "                df_acuity = df_run[df_run['acuity'] == acuity_val]\n",
    "                if len(df_acuity) > 0:\n",
    "                    los_difference = np.median(df_acuity['ed_los']) - np.median(target_results[acuity_val])\n",
    "                    dict_los_difference[acuity_val].append(los_difference)\n",
    "    elif indicator_type == 'disposition':\n",
    "        dict_los_difference = {}\n",
    "        for disposition_val in list_disposition:\n",
    "            dict_los_difference[disposition_val] = []\n",
    "            for df_run in df_results_per_run:\n",
    "                df_disposition = df_run[df_run['disposition'] == disposition_val]\n",
    "                if len(df_disposition) > 0:\n",
    "                    los_difference = np.median(df_disposition['ed_los']) - np.median(target_results[disposition_val])\n",
    "                    dict_los_difference[disposition_val].append(los_difference)\n",
    "    elif indicator_type == 'complexity':\n",
    "        dict_los_difference = {}\n",
    "        for complexity_val in list_complexity:\n",
    "            dict_los_difference[complexity_val] = []\n",
    "            for df_run in df_results_per_run:\n",
    "                df_complexity = df_run[df_run['complexity'] == complexity_val]\n",
    "                if len(df_complexity) > 0:\n",
    "                    los_difference = np.median(df_complexity['ed_los']) - np.median(target_results[complexity_val])\n",
    "                    dict_los_difference[complexity_val].append(los_difference)\n",
    "    elif indicator_type == 'acuity-disposition':\n",
    "        dict_los_difference = {}\n",
    "        for acuity_val in list_acuity:\n",
    "            for disposition_val in list_disposition:\n",
    "                dict_los_difference[f'{acuity_val}_{disposition_val}'] = []\n",
    "\n",
    "            for df_run in df_results_per_run:\n",
    "                for disposition_val in list_disposition:\n",
    "                    df_group = df_run[(df_run['acuity'] == acuity_val) & (df_run['disposition'] == disposition_val)]\n",
    "                    if len(df_group) > 0:\n",
    "                        los_difference = np.median(df_group['ed_los']) - np.median(target_results[f'{acuity_val}_{disposition_val}'])\n",
    "                        dict_los_difference[f'{acuity_val}_{disposition_val}'].append(los_difference)\n",
    "    elif indicator_type == 'acuity-complexity':\n",
    "        dict_los_difference = {}\n",
    "        for acuity_val in list_acuity:\n",
    "            for complexity_val in list_complexity:\n",
    "                dict_los_difference[f'{acuity_val}_{complexity_val}'] = []\n",
    "\n",
    "            for df_run in df_results_per_run:\n",
    "                for complexity_val in list_complexity:\n",
    "                    df_group = df_run[(df_run['acuity'] == acuity_val) & (df_run['complexity'] == complexity_val)]\n",
    "                    if len(df_group) > 0:\n",
    "                        los_difference = np.median(df_group['ed_los']) - np.median(target_results[f'{acuity_val}_{complexity_val}'])\n",
    "                        dict_los_difference[f'{acuity_val}_{complexity_val}'].append(los_difference)\n",
    "\n",
    "    return dict_los_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_los_difference(dict_los_difference, sorted_key, sorted_labels, color, xlabel=None, title=None):\n",
    "    plot_this = [dict_los_difference[key] for key in sorted_key]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(0.4*len(sorted_key),1.5), sharey=True, sharex=False)\n",
    "    fig.dpi = 600\n",
    "\n",
    "    axes.boxplot(plot_this, vert=True, flierprops={'markersize': 2}, widths=0.2, medianprops={'color': '#D55E00'}, showfliers=False, whiskerprops={'color': color}, capprops={'color': color}, boxprops={'color': color, 'facecolor': color}, patch_artist=True)\n",
    "\n",
    "    for patch in axes.patches:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, .3))\n",
    "\n",
    "    default_grid_color = plt.rcParams['grid.color']\n",
    "    plt.axhline(1, color=default_grid_color, linewidth=0.5, zorder=0, linestyle='--')\n",
    "    plt.axhline(0, color=default_grid_color, linewidth=1, zorder=0, linestyle='-')\n",
    "    plt.axhline(-1, color=default_grid_color, linewidth=0.5, zorder=0, linestyle='--')\n",
    "    axes.set_ylim(-6, 6)\n",
    "    axes.set_xticklabels(sorted_labels)\n",
    "    axes.set_yticks(np.arange(-6,6.1,2))\n",
    "    plt.tick_params(axis='both', which='both', labelsize='small')\n",
    "    plt.ylabel('LOS difference', fontsize='small')\n",
    "    plt.xlabel(xlabel, fontsize='small')\n",
    "    plt.title(title, fontsize='small')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_los_difference_vert(dict_los_difference, sorted_key, sorted_labels, color, xlabel=None, title=None):\n",
    "    plot_this = [dict_los_difference[key] for key in sorted_key]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(1.6,0.35*len(sorted_key)), sharey=True, sharex=False)\n",
    "    fig.dpi = 600\n",
    "\n",
    "    axes.boxplot(plot_this[::-1], vert=False, flierprops={'markersize': 2}, widths=0.35, medianprops={'color': '#D55E00'}, showfliers=False, whiskerprops={'color': color}, capprops={'color': color}, boxprops={'color': color, 'facecolor': color}, patch_artist=True)\n",
    "\n",
    "    for patch in axes.patches:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, .3))\n",
    "\n",
    "    default_grid_color = plt.rcParams['grid.color']\n",
    "    plt.axvline(1, color=default_grid_color, linewidth=0.5, zorder=0, linestyle=':')\n",
    "    plt.axvline(0, color=default_grid_color, linewidth=1, zorder=0, linestyle='-')\n",
    "    plt.axvline(-1, color=default_grid_color, linewidth=0.5, zorder=0, linestyle=':')\n",
    "    axes.set_xlim(-5, 5)\n",
    "    axes.set_yticklabels(sorted_labels[::-1])\n",
    "    axes.set_xticks(np.arange(-4,4.1,2))\n",
    "    plt.tick_params(axis='both', which='both', labelsize='small')\n",
    "    plt.xlabel('Relative median LOS', fontsize='small')\n",
    "    plt.ylabel(xlabel, fontsize='small')\n",
    "    plt.title(title, fontsize='small')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acuity_val in list_acuity:\n",
    "    df_test = df_pro_concatenated[df_pro_concatenated['acuity'] == acuity_val]\n",
    "    print(acuity_val, np.median(df_test['ed_los']) - np.median(target_los_acuity[acuity_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, color in zip([df_pro_per_run, df_ret_per_run], ['#0072B2', '#009E73']):\n",
    "    dict_los_difference_acuity = calculate_los_difference(df_cohort, target_los_acuity, 'acuity')\n",
    "    plot_los_difference_vert(dict_los_difference_acuity, list_acuity, ['1', '2', '3', '4', '5'], color, 'Acuity', 'All patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, color in zip([df_pro_per_run, df_ret_per_run], ['#0072B2', '#009E73']):\n",
    "    dict_los_difference_disposition = calculate_los_difference(df_cohort, target_los_disposition, 'disposition')\n",
    "    plot_los_difference_vert(dict_los_difference_disposition, list_disposition, ['Home', 'Ward', 'ICU'], color, 'Disposition', 'All patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, color in zip([df_pro_per_run, df_ret_per_run], ['#0072B2', '#009E73']):\n",
    "    dict_los_difference_complexity = calculate_los_difference(df_cohort, target_los_complexity, 'complexity')\n",
    "    plot_los_difference_vert(dict_los_difference_complexity, list_complexity, ['Low', 'Moderate', 'High'], color, 'Complexity', 'All patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, color in zip([df_pro_per_run, df_ret_per_run], ['#0072B2', '#009E73']):\n",
    "    for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "        sorted_key = []\n",
    "        for disposition_val in list_disposition:\n",
    "            sorted_key.append(f'{acuity_val}_{disposition_val}')\n",
    "\n",
    "        dict_los_difference_acuity_disposition = calculate_los_difference(df_cohort, target_los_acuity_disposition, 'acuity-disposition')\n",
    "        plot_los_difference_vert(dict_los_difference_acuity_disposition, sorted_key, ['Home', 'Ward', 'ICU'], color, 'Disposition', f'Acuity {acuity_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_cohort, color in zip([df_pro_per_run, df_ret_per_run], ['#0072B2', '#009E73']):\n",
    "    for acuity_val in ['1', '2', '3', '4', '5']:\n",
    "        sorted_key = []\n",
    "        for complexity_val in list_complexity:\n",
    "            sorted_key.append(f'{acuity_val}_{complexity_val}')\n",
    "\n",
    "        dict_los_difference_acuity_complexity = calculate_los_difference(df_cohort, target_los_acuity_complexity, 'acuity-complexity')\n",
    "        plot_los_difference_vert(dict_los_difference_acuity_complexity, sorted_key, ['Low', 'Moderate', 'High'], color, 'Complexity', f'Acuity {acuity_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underrepresented_group(df_cohort, frequency_threshold):\n",
    "    list_name, list_relative_frequency, list_los_difference = [], [], []\n",
    "    for acuity_val in list_acuity:\n",
    "        for disposition_val in list_disposition:\n",
    "            df_group = df_cohort[(df_cohort['acuity'] == acuity_val) & (df_cohort['disposition'] == disposition_val)]\n",
    "\n",
    "            if len(df_group) > 0:\n",
    "                list_name.append(f'{acuity_val}_{disposition_val}')\n",
    "                list_relative_frequency.append(len(target_los_acuity_disposition[f'{acuity_val}_{disposition_val}']) / len(target_los_acuity[acuity_val]))\n",
    "                list_los_difference.append(np.median(df_group['ed_los']) - np.median(target_los_acuity_disposition[f'{acuity_val}_{disposition_val}']))\n",
    "\n",
    "        for complexity_val in list_complexity:\n",
    "            df_group = df_cohort[(df_cohort['acuity'] == acuity_val) & (df_cohort['complexity'] == complexity_val)]\n",
    "\n",
    "            if len(df_group) > 0:\n",
    "                list_name.append(f'{acuity_val}_{complexity_val}')\n",
    "                list_relative_frequency.append(len(target_los_acuity_complexity[f'{acuity_val}_{complexity_val}']) / len(target_los_acuity[acuity_val]))\n",
    "                list_los_difference.append(np.median(df_group['ed_los']) - np.median(target_los_acuity_complexity[f'{acuity_val}_{complexity_val}']))\n",
    "\n",
    "    return (list_name, list_relative_frequency, list_los_difference)\n",
    "\n",
    "FREQUENCY_THRESHOLD = 0.15\n",
    "name_pro, freq_pro, diff_pro = get_underrepresented_group(df_pro_concatenated, FREQUENCY_THRESHOLD)\n",
    "name_ret, freq_ret, diff_ret = get_underrepresented_group(df_ret_concatenated, FREQUENCY_THRESHOLD)\n",
    "\n",
    "assert set(name_pro) == set(name_ret), 'Patient groups names should be the same'\n",
    "assert set(freq_pro) == set(freq_ret), 'Relative frequency should be the same'\n",
    "\n",
    "for name_val, freq_val, pro_val, ret_val in zip(name_pro, freq_pro, diff_pro, diff_ret):\n",
    "    if freq_val < FREQUENCY_THRESHOLD:\n",
    "        print(f'{name_val}\\t{freq_val*100}\\t{pro_val}\\t{ret_val}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_col, frequency_col, value_col = [], [], []\n",
    "pro_high, pro_low = [], []\n",
    "for freq_val, diff_val in zip(freq_pro, diff_pro):\n",
    "    if freq_val > FREQUENCY_THRESHOLD:\n",
    "        pro_high.append(abs(diff_val))\n",
    "    else:\n",
    "        pro_low.append(abs(diff_val))\n",
    "\n",
    "pro_mean = [np.mean(pro_high), np.mean(pro_low)]\n",
    "for idx, mean_val in enumerate(pro_mean):\n",
    "    cohort_col.append('Prospective cohort')\n",
    "\n",
    "    if idx == 0:\n",
    "        frequency_col.append('Low')\n",
    "    else:\n",
    "        frequency_col.append('High')\n",
    "\n",
    "    value_col.append(mean_val)\n",
    "\n",
    "ret_high, ret_low = [], []\n",
    "for freq_val, diff_val in zip(freq_ret, diff_ret):\n",
    "    if freq_val > FREQUENCY_THRESHOLD:\n",
    "        ret_high.append(abs(diff_val))\n",
    "    else:\n",
    "        ret_low.append(abs(diff_val))\n",
    "\n",
    "ret_mean = [np.mean(ret_high), np.mean(ret_low)]\n",
    "for idx, mean_val in enumerate(ret_mean):\n",
    "    cohort_col.append('Retrospective cohort')\n",
    "\n",
    "    if idx == 0:\n",
    "        frequency_col.append('Low')\n",
    "    else:\n",
    "        frequency_col.append('High')\n",
    "\n",
    "    value_col.append(mean_val)\n",
    "\n",
    "df_representation = pd.DataFrame({'Cohort type': cohort_col, 'Data frequency': frequency_col, 'Mean LOS difference': value_col})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(2,1.5), sharey=True, sharex=False)\n",
    "fig.dpi = 600\n",
    "\n",
    "ax = sns.barplot(data=df_representation, y='Data frequency', x='Mean LOS difference', hue='Cohort type', palette=['#0072B2', '#009E73'], width=0.6, gap=0.1, zorder=3)\n",
    "for idx, container in enumerate(ax.containers):\n",
    "    if idx == 0:\n",
    "        ax.bar_label(container, fontsize=8, fmt='%.1f', color='#0072B2', padding=2)\n",
    "    else:\n",
    "        ax.bar_label(container, fontsize=8, fmt='%.1f', color='#009E73', padding=2)\n",
    "\n",
    "sns.move_legend(ax, 'lower center', bbox_to_anchor=(.5, 1), ncol=2, title='Cohort type', frameon=False, columnspacing=2, handlelength=0.8, handletextpad=0.8, reverse=False, fontsize='small')\n",
    "\n",
    "plt.xlabel('Mean of the absolute differences between the\\ntarget and aggregated median LOS values', fontsize='small')\n",
    "plt.xlim(0,4)\n",
    "plt.xticks([0, 1, 2, 3, 4])\n",
    "ax.set_xticks([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4], minor=True)\n",
    "\n",
    "plt.ylabel('')\n",
    "ax.set_yticks(range(2))\n",
    "ax.set_yticklabels(['Well-represented\\npatient groups\\n(n = 19)', 'Under-represented\\npatient groups\\n(n = 8)'])\n",
    "\n",
    "plt.grid(axis='x', which='minor', linewidth=0.5)\n",
    "plt.grid(axis='x', which='major', linewidth=0.5)\n",
    "\n",
    "plt.tick_params(axis='both', which='both', labelsize='small')\n",
    "legend = ax.get_legend()\n",
    "title = legend.get_title()\n",
    "title.set_fontsize('small')\n",
    "ax.grid(True, axis='x', which='both', linestyle=':')\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_zorder(3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
